{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_bucket_name_text = 'robb.pdf.bucket'\n",
    "region = 'us-east-1'\n",
    "\n",
    "lambda_layer_arn='arn:aws:lambda:us-east-1:638139650817:layer:robb_bedrock_lambda_layer:1'\n",
    "lambda_execution_role = \"arn:aws:iam::638139650817:role/RobbLambdaRole\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the map prompt to disk as map_prompt_template.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile map_prompt_template.txt\n",
    "Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the summarization prompt to disk as combine_prompt_template.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile combine_prompt_template.txt\n",
    "combine_prompt = \"\"\"\n",
    "Write a concise summary of the following text delimited by triple backquotes that includes the following elements:\n",
    "* A title that accurately reflects the content of the text.\n",
    "* An introduction paragraph that provides an overview of the topic.\n",
    "* Approximately twenty bullet points that list the key points of the text.\n",
    "* A conclusion paragraph that summarizes the main points of the text.\n",
    "```{text}```\n",
    "BULLET POINT SUMMARY:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the lambda function to disk PDFProcessLambdaFunction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile PDFProcessLambdaFunction.py\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "import json \n",
    "#import uuid\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "#from langchain import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "\n",
    "modelId = \"amazon.titan-tg1-large\"\n",
    "region = 'us-east-1'\n",
    "chunk_size = 1000\n",
    "chunk_overlapp = 100\n",
    "bedrock_max_token = 4096\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name=region)\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = event['Records'][0]['s3']['object']['key']\n",
    "    \n",
    "    print(\"The bucket is: \" + bucket)\n",
    "    print(\"The key is: \" + key)\n",
    "    \n",
    "\n",
    "    \n",
    "    if \"pdf/\"  in key: \n",
    "        \n",
    "        print(\"This app is working on a  with pdf file.\")\n",
    "        return_status = lambda_pdf_processor(bucket, key)\n",
    "        \n",
    "\n",
    "def lambda_pdf_processor( bucket, key ):\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        pdf_file = s3_client.get_object(Bucket=bucket, Key=key)[\"Body\"].read()\n",
    "        reader = PdfReader(io.BytesIO(pdf_file))\n",
    "        \n",
    "        print(\"Number of reader pages: \"+ str(len(reader.pages)) )\n",
    "        \n",
    "        pages = []\n",
    "        for pp in reader.pages:\n",
    "            pages.append(pp.extract_text() )\n",
    "            \n",
    "        print(\"Number of PDF pages: \" + str(len(pages)) )\n",
    "        #print(\"Pages ***************\")\n",
    "        #print(pages[0])\n",
    "        #print(pages[1])\n",
    "        #print(\"*****************\")\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "             separators=[\"\\n\\n\", \"\\n\"], chunk_size=chunk_size, chunk_overlap=chunk_overlapp)\n",
    "        docs = text_splitter.create_documents(pages)\n",
    "         \n",
    "        print(\"Number of created docs: \" + str(len(docs)) )\n",
    "       # print(\"docs ***************\")\n",
    "        #print(docs[0])\n",
    "        #print(docs[1])\n",
    "        #print(\"*****************\")\n",
    "        \n",
    "        print(\"Calling lambda summarize\")\n",
    "        lambda_summarize( docs )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f\"Error occurred: {e}\")\n",
    "            }\n",
    "\n",
    "def lambda_summarize( docs : [str]):\n",
    "    \n",
    "    llm_model = Bedrock(\n",
    "        model_id=modelId,\n",
    "        model_kwargs={\n",
    "            \"maxTokenCount\": bedrock_max_token,\n",
    "            \"stopSequences\": [],\n",
    "            \"temperature\": 0,\n",
    "            \"topP\": 1,\n",
    "        },\n",
    "        client=bedrock_runtime, \n",
    "    )\n",
    "    #Load prompts\n",
    "    with open('combine_prompt_template.txt', \"r\") as file:\n",
    "        combine_prompt_template= file.read()\n",
    "        \n",
    "    print(\"Loaded the combine_prompt_template.txt.\")\n",
    "        \n",
    "    combine_prompt_template = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
    "        \n",
    "    with open('map_prompt_template.txt', \"r\") as file:\n",
    "        map_prompt_template= file.read()\n",
    "    \n",
    "    print(\"Loaded the map_prompt_template.txt.\")\n",
    "        \n",
    "    map_prompt_template = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "    \n",
    "    summary_chain = load_summarize_chain(llm=llm_model, \n",
    "                                         chain_type=\"map_reduce\", \n",
    "                                         verbose=True,  \n",
    "                                         map_prompt=map_prompt_template, \n",
    "                                         combine_prompt=combine_prompt_template) \n",
    "                                        #, token_max = reduce_chain_max_token )\n",
    "    print(\"Calling chain invoke ***************\")                                  \n",
    "    summary_string = summary_chain.invoke(docs)\n",
    "    #summary_string = \"done\"\n",
    "    print(\"Summary ***********************\")\n",
    "    print( summary_string)\n",
    "    print(\"End of Summary ***********************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip the Lambda code and prompts,and upload them to AWS Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.Lambda_Helper import Lambda_Helper\n",
    "\n",
    "lambda_helper = Lambda_Helper(region, lambda_layer_arn, lambda_execution_role)\n",
    "# deploy_function\n",
    "# add_lambda_trigger\n",
    "\n",
    "pdf_lambda_function_name = \"PDFProcessLambdaFunction\"\n",
    "\n",
    "\n",
    "lambda_helper.deploy_function( [\"PDFProcessLambdaFunction.py\",\"map_prompt_template.txt\", \"combine_prompt_template.txt\"],function_name=pdf_lambda_function_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the S3/Lambda notification for PDF upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rule_list = [ {'Name': 'suffix','Value': 'pdf'},{'Name': 'prefix','Value': 'pdf/'}]\n",
    "\n",
    "lambda_helper.add_lambda_trigger(pdf_bucket_name_text, filter_rule_list=filter_rule_list, function_name=pdf_lambda_function_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload pdf to be summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.S3_Helper import S3_Helper\n",
    "\n",
    "s3_helper = S3_Helper(region)\n",
    "# upload_file\n",
    "# download_object \n",
    "# list_objects\n",
    "\n",
    "s3_helper.upload_file_to_bucket(pdf_bucket_name_text, 'data/letter.pdf', 'pdf/letter.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def DeleteLocalFile( file_name:str):\n",
    "  if os.path.exists(file_name):\n",
    "    os.remove(file_name)\n",
    "    \n",
    "DeleteLocalFile(\"PDFProcessLambdaFunction.py\")\n",
    "DeleteLocalFile(\"PDFProcessLambdaFunction.zip\")\n",
    "DeleteLocalFile(\"combine_prompt_template.txt\")\n",
    "DeleteLocalFile(\"map_prompt_template.txt\")\n",
    "DeleteLocalFile(\"results.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
